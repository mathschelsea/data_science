{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6PWb0Ym5epNkNOUEpfDBh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathschelsea/data_science/blob/feature%2Fllm_underthehood/notebooks/llm_underthehood.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "torch.manual_seed(7663);"
      ],
      "metadata": {
        "id": "66jy3w9NN_qm"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eECSGuSGC9xR",
        "outputId": "cb8ce36e-a7ab-4c3b-de5e-2f1ba12e1241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-05 18:41:25--  https://raw.githubusercontent.com/mathschelsea/data_science/feature/llm_underthehood/data/raw/bandt_bogus_script.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25535 (25K) [text/plain]\n",
            "Saving to: ‘bandt_bogus_script.txt’\n",
            "\n",
            "\rbandt_bogus_script.   0%[                    ]       0  --.-KB/s               \rbandt_bogus_script. 100%[===================>]  24.94K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-10-05 18:41:25 (21.3 MB/s) - ‘bandt_bogus_script.txt’ saved [25535/25535]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Downloadeding Bill & Ted's Bogus Journey\n",
        "!wget https://raw.githubusercontent.com/mathschelsea/data_science/feature/llm_underthehood/data/raw/bandt_bogus_script.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading in the script\n",
        "with open('bandt_bogus_script.txt', 'r', encoding='utf-8') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "oSyBWsX_GS2u"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Length of dataset in characters: {len(text)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbwytzObGtAa",
        "outputId": "52e34297-e53a-4a27-dbcd-16cfd9267530"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset in characters: 24643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at first 1000 characters\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd3T9YZaG3VO",
        "outputId": "068fcfd7-f756-490b-88b0-7fdb01bc89c3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is time. \n",
            "They've reached the second crucial turning point in their destiny. Their message is about to \n",
            "reach millions. \n",
            "But... we will change all that. When our mission is successful... ...no longer will the world \n",
            "be dominated... \n",
            "...by the legacy of these two fools! No longer will we hear this: \n",
            "We will stop them now! \n",
            "Brothers and sisters... \n",
            "...are we ready? \n",
            "- Greetings, my excellent pupils. - Station. \n",
            "Let's continue our study of the physics of acoustical reverberation. Meet today's most non-bogus \n",
            "guest speakers. \n",
            "Say hello to Thomas Edison. \n",
            "Hello there. \n",
            "To help us on the musical side: Johann Sebastian Bach. \n",
            "And Sir James Martin \n",
            "of Faith No More... \n",
            "...founder of the Faith No More Spiritual and Theological Center. - Station! \n",
            "- Station! \n",
            "And a special treat \n",
            "from the 23rd century: \n",
            "Miss Ria Paschelle. \n",
            "Miss Paschelle is \n",
            "the inventor of the... \n",
            "...statiophonicoxygeneticamp \n",
            "lifiagraphiphonideliverberator. Hard to imagine the world \n",
            "without them, isn't it? \n",
            "Remember, this\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Listing all the unique characters in the text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(f'Vocabulary size: {vocab_size}')\n",
        "print(f'All unique characters: {\"\".join(chars)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eVE9k1qHMWD",
        "outputId": "39d42b87-9b79-43fc-9aaf-b10bb0dfe2aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 67\n",
            "All unique characters: \n",
            " !\"$',-.0123567:?ABCDEFGHIJKLMNOPQRSTUWYabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Developing a strategy to tokenise the text i.e. convert the raw string text to some sequence of integers"
      ],
      "metadata": {
        "id": "PxkPQzY4KvR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a mapping from characters to integers and back again\n",
        "\n",
        "# Encode (string to index)\n",
        "stoi = { ch:i for i,ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "\n",
        "# Decode (index to string)\n",
        "itos = { i:ch for i,ch in enumerate(chars)}\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "print(encode('dude'))\n",
        "print(decode(encode('dude')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PA-wZGELUjj",
        "outputId": "1429fb91-0de3-423d-d67d-cb0a73d36e0b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[44, 61, 44, 45]\n",
            "dude\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sub-word tokeniser: SentencePiece\n",
        "# GPT uses TikToken BPE tokeniser"
      ],
      "metadata": {
        "id": "aebS7Xw9Mex2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the entire dataset and store it into a torch tensor\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(f'Shape: {data.shape}')\n",
        "print(f'Data type: {data.dtype}')\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR1rVzZsMjEu",
        "outputId": "878a7bdf-dde2-4657-d394-5ad39a3f12d1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([24643])\n",
            "Data type: torch.int64\n",
            "tensor([26, 60,  1, 49, 59,  1, 60, 49, 53, 45,  8,  1,  0, 37, 48, 45, 65,  5,\n",
            "        62, 45,  1, 58, 45, 41, 43, 48, 45, 44,  1, 60, 48, 45,  1, 59, 45, 43,\n",
            "        55, 54, 44,  1, 43, 58, 61, 43, 49, 41, 52,  1, 60, 61, 58, 54, 49, 54,\n",
            "        47,  1, 56, 55, 49, 54, 60,  1, 49, 54,  1, 60, 48, 45, 49, 58,  1, 44,\n",
            "        45, 59, 60, 49, 54, 65,  8,  1, 37, 48, 45, 49, 58,  1, 53, 45, 59, 59,\n",
            "        41, 47, 45,  1, 49, 59,  1, 41, 42, 55, 61, 60,  1, 60, 55,  1,  0, 58,\n",
            "        45, 41, 43, 48,  1, 53, 49, 52, 52, 49, 55, 54, 59,  8,  1,  0, 19, 61,\n",
            "        60,  8,  8,  8,  1, 63, 45,  1, 63, 49, 52, 52,  1, 43, 48, 41, 54, 47,\n",
            "        45,  1, 41, 52, 52,  1, 60, 48, 41, 60,  8,  1, 39, 48, 45, 54,  1, 55,\n",
            "        61, 58,  1, 53, 49, 59, 59, 49, 55, 54,  1, 49, 59,  1, 59, 61, 43, 43,\n",
            "        45, 59, 59, 46, 61, 52,  8,  8,  8,  1,  8,  8,  8, 54, 55,  1, 52, 55,\n",
            "        54, 47, 45, 58,  1, 63, 49, 52, 52,  1, 60, 48, 45,  1, 63, 55, 58, 52,\n",
            "        44,  1,  0, 42, 45,  1, 44, 55, 53, 49, 54, 41, 60, 45, 44,  8,  8,  8,\n",
            "         1,  0,  8,  8,  8, 42, 65,  1, 60, 48, 45,  1, 52, 45, 47, 41, 43, 65,\n",
            "         1, 55, 46,  1, 60, 48, 45, 59, 45,  1, 60, 63, 55,  1, 46, 55, 55, 52,\n",
            "        59,  2,  1, 31, 55,  1, 52, 55, 54, 47, 45, 58,  1, 63, 49, 52, 52,  1,\n",
            "        63, 45,  1, 48, 45, 41, 58,  1, 60, 48, 49, 59, 16,  1,  0, 39, 45,  1,\n",
            "        63, 49, 52, 52,  1, 59, 60, 55, 56,  1, 60, 48, 45, 53,  1, 54, 55, 63,\n",
            "         2,  1,  0, 19, 58, 55, 60, 48, 45, 58, 59,  1, 41, 54, 44,  1, 59, 49,\n",
            "        59, 60, 45, 58, 59,  8,  8,  8,  1,  0,  8,  8,  8, 41, 58, 45,  1, 63,\n",
            "        45,  1, 58, 45, 41, 44, 65, 17,  1,  0,  7,  1, 24, 58, 45, 45, 60, 49,\n",
            "        54, 47, 59,  6,  1, 53, 65,  1, 45, 64, 43, 45, 52, 52, 45, 54, 60,  1,\n",
            "        56, 61, 56, 49, 52, 59,  8,  1,  7,  1, 36, 60, 41, 60, 49, 55, 54,  8,\n",
            "         1,  0, 29, 45, 60,  5, 59,  1, 43, 55, 54, 60, 49, 54, 61, 45,  1, 55,\n",
            "        61, 58,  1, 59, 60, 61, 44, 65,  1, 55, 46,  1, 60, 48, 45,  1, 56, 48,\n",
            "        65, 59, 49, 43, 59,  1, 55, 46,  1, 41, 43, 55, 61, 59, 60, 49, 43, 41,\n",
            "        52,  1, 58, 45, 62, 45, 58, 42, 45, 58, 41, 60, 49, 55, 54,  8,  1, 30,\n",
            "        45, 45, 60,  1, 60, 55, 44, 41, 65,  5, 59,  1, 53, 55, 59, 60,  1, 54,\n",
            "        55, 54,  7, 42, 55, 47, 61, 59,  1,  0, 47, 61, 45, 59, 60,  1, 59, 56,\n",
            "        45, 41, 51, 45, 58, 59,  8,  1,  0, 36, 41, 65,  1, 48, 45, 52, 52, 55,\n",
            "         1, 60, 55,  1, 37, 48, 55, 53, 41, 59,  1, 22, 44, 49, 59, 55, 54,  8,\n",
            "         1,  0, 25, 45, 52, 52, 55,  1, 60, 48, 45, 58, 45,  8,  1,  0, 37, 55,\n",
            "         1, 48, 45, 52, 56,  1, 61, 59,  1, 55, 54,  1, 60, 48, 45,  1, 53, 61,\n",
            "        59, 49, 43, 41, 52,  1, 59, 49, 44, 45, 16,  1, 27, 55, 48, 41, 54, 54,\n",
            "         1, 36, 45, 42, 41, 59, 60, 49, 41, 54,  1, 19, 41, 43, 48,  8,  1,  0,\n",
            "        18, 54, 44,  1, 36, 49, 58,  1, 27, 41, 53, 45, 59,  1, 30, 41, 58, 60,\n",
            "        49, 54,  1,  0, 55, 46,  1, 23, 41, 49, 60, 48,  1, 31, 55,  1, 30, 55,\n",
            "        58, 45,  8,  8,  8,  1,  0,  8,  8,  8, 46, 55, 61, 54, 44, 45, 58,  1,\n",
            "        55, 46,  1, 60, 48, 45,  1, 23, 41, 49, 60, 48,  1, 31, 55,  1, 30, 55,\n",
            "        58, 45,  1, 36, 56, 49, 58, 49, 60, 61, 41, 52,  1, 41, 54, 44,  1, 37,\n",
            "        48, 45, 55, 52, 55, 47, 49, 43, 41, 52,  1, 20, 45, 54, 60, 45, 58,  8,\n",
            "         1,  7,  1, 36, 60, 41, 60, 49, 55, 54,  2,  1,  0,  7,  1, 36, 60, 41,\n",
            "        60, 49, 55, 54,  2,  1,  0, 18, 54, 44,  1, 41,  1, 59, 56, 45, 43, 49,\n",
            "        41, 52,  1, 60, 58, 45, 41, 60,  1,  0, 46, 58, 55, 53,  1, 60, 48, 45,\n",
            "         1, 11, 12, 58, 44,  1, 43, 45, 54, 60, 61, 58, 65, 16,  1,  0, 30, 49,\n",
            "        59, 59,  1, 35, 49, 41,  1, 33, 41, 59, 43, 48, 45, 52, 52, 45,  8,  1,\n",
            "         0, 30, 49, 59, 59,  1, 33, 41, 59, 43, 48, 45, 52, 52, 45,  1, 49, 59,\n",
            "         1,  0, 60, 48, 45,  1, 49, 54, 62, 45, 54, 60, 55, 58,  1, 55, 46,  1,\n",
            "        60, 48, 45,  8,  8,  8,  1,  0,  8,  8,  8, 59, 60, 41, 60, 49, 55, 56,\n",
            "        48, 55, 54, 49, 43, 55, 64, 65, 47, 45, 54, 45, 60, 49, 43, 41, 53, 56,\n",
            "         1,  0, 52, 49, 46, 49, 41, 47, 58, 41, 56, 48, 49, 56, 48, 55, 54, 49,\n",
            "        44, 45, 52, 49, 62, 45, 58, 42, 45, 58, 41, 60, 55, 58,  8,  1, 25, 41,\n",
            "        58, 44,  1, 60, 55,  1, 49, 53, 41, 47, 49, 54, 45,  1, 60, 48, 45,  1,\n",
            "        63, 55, 58, 52, 44,  1,  0, 63, 49, 60, 48, 55, 61, 60,  1, 60, 48, 45,\n",
            "        53,  6,  1, 49, 59, 54,  5, 60,  1, 49, 60, 17,  1,  0, 35, 45, 53, 45,\n",
            "        53, 42, 45, 58,  6,  1, 60, 48, 49, 59])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data into train and validation sets\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "6vU-c2BTOUf4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We now want to start plugging these integer (text) sequences into the transformer so that it can be trained\n",
        "# We can't push the entire text through the transformed all at once, we need to push 'chunks' of the text through"
      ],
      "metadata": {
        "id": "SOnJQyjRRvEL"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8 # context length\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiYp5fwoSRv2",
        "outputId": "de48bede-6d07-4aba-b04f-aaea10d137c5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([26, 60,  1, 49, 59,  1, 60, 49, 53])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f'When the input is {context} the target is {target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX3XSouOSX54",
        "outputId": "f6488b07-b9ad-4e3c-f0b6-e1f78bf48f94"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When the input is tensor([26]) the target is 60\n",
            "When the input is tensor([26, 60]) the target is 1\n",
            "When the input is tensor([26, 60,  1]) the target is 49\n",
            "When the input is tensor([26, 60,  1, 49]) the target is 59\n",
            "When the input is tensor([26, 60,  1, 49, 59]) the target is 1\n",
            "When the input is tensor([26, 60,  1, 49, 59,  1]) the target is 60\n",
            "When the input is tensor([26, 60,  1, 49, 59,  1, 60]) the target is 49\n",
            "When the input is tensor([26, 60,  1, 49, 59,  1, 60, 49]) the target is 53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# When feeding the transformer we want to pass it multiple sequences/chunks e.g. a batch of sequences/chunks\n",
        "# So we need to create one more dimension (the batch dimension)"
      ],
      "metadata": {
        "id": "6tTDdn5SS-4X"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4 # the numnber of independent sequences that will be processed in parallel\n",
        "block_size = 8 # the maximum context length for predictions\n",
        "\n",
        "def get_batch(split):\n",
        "  # generate a small batch of data or inputs x and targets y\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data)-block_size, (batch_size,)) # 4 random numbers between 0 and length of data minus block size\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('Inputs:')\n",
        "print(xb)\n",
        "print(f'Input shape: {xb.shape}')\n",
        "print('Targets')\n",
        "print(yb)\n",
        "print(f'Targets shape: {yb.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iTzndQLURqO",
        "outputId": "7293a180-7081-4c7e-e31d-e6a8b6f1a6ea"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "tensor([[42, 52, 55, 55, 44,  8,  1,  0],\n",
            "        [26,  1, 63, 55, 58, 51,  1, 55],\n",
            "        [ 1,  0, 37, 48, 41, 54, 51, 59],\n",
            "        [ 8,  1,  0, 37, 48, 45, 65,  1]])\n",
            "Input shape: torch.Size([4, 8])\n",
            "Targets\n",
            "tensor([[52, 55, 55, 44,  8,  1,  0,  7],\n",
            "        [ 1, 63, 55, 58, 51,  1, 55, 61],\n",
            "        [ 0, 37, 48, 41, 54, 51, 59,  6],\n",
            "        [ 1,  0, 37, 48, 45, 65,  1, 60]])\n",
            "Targets shape: torch.Size([4, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for b in range(batch_size):\n",
        "  for t in range(block_size):\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f'When the input is {context} the output is {target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCt10zgHVB0K",
        "outputId": "73fd26e1-8cfd-4c34-e75a-a5dc16824da0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When the input is tensor([42]) the output is 52\n",
            "When the input is tensor([42, 52]) the output is 55\n",
            "When the input is tensor([42, 52, 55]) the output is 55\n",
            "When the input is tensor([42, 52, 55, 55]) the output is 44\n",
            "When the input is tensor([42, 52, 55, 55, 44]) the output is 8\n",
            "When the input is tensor([42, 52, 55, 55, 44,  8]) the output is 1\n",
            "When the input is tensor([42, 52, 55, 55, 44,  8,  1]) the output is 0\n",
            "When the input is tensor([42, 52, 55, 55, 44,  8,  1,  0]) the output is 7\n",
            "When the input is tensor([26]) the output is 1\n",
            "When the input is tensor([26,  1]) the output is 63\n",
            "When the input is tensor([26,  1, 63]) the output is 55\n",
            "When the input is tensor([26,  1, 63, 55]) the output is 58\n",
            "When the input is tensor([26,  1, 63, 55, 58]) the output is 51\n",
            "When the input is tensor([26,  1, 63, 55, 58, 51]) the output is 1\n",
            "When the input is tensor([26,  1, 63, 55, 58, 51,  1]) the output is 55\n",
            "When the input is tensor([26,  1, 63, 55, 58, 51,  1, 55]) the output is 61\n",
            "When the input is tensor([1]) the output is 0\n",
            "When the input is tensor([1, 0]) the output is 37\n",
            "When the input is tensor([ 1,  0, 37]) the output is 48\n",
            "When the input is tensor([ 1,  0, 37, 48]) the output is 41\n",
            "When the input is tensor([ 1,  0, 37, 48, 41]) the output is 54\n",
            "When the input is tensor([ 1,  0, 37, 48, 41, 54]) the output is 51\n",
            "When the input is tensor([ 1,  0, 37, 48, 41, 54, 51]) the output is 59\n",
            "When the input is tensor([ 1,  0, 37, 48, 41, 54, 51, 59]) the output is 6\n",
            "When the input is tensor([8]) the output is 1\n",
            "When the input is tensor([8, 1]) the output is 0\n",
            "When the input is tensor([8, 1, 0]) the output is 37\n",
            "When the input is tensor([ 8,  1,  0, 37]) the output is 48\n",
            "When the input is tensor([ 8,  1,  0, 37, 48]) the output is 45\n",
            "When the input is tensor([ 8,  1,  0, 37, 48, 45]) the output is 65\n",
            "When the input is tensor([ 8,  1,  0, 37, 48, 45, 65]) the output is 1\n",
            "When the input is tensor([ 8,  1,  0, 37, 48, 45, 65,  1]) the output is 60\n"
          ]
        }
      ]
    }
  ]
}